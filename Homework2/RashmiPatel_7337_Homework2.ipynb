{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3a910c5",
   "metadata": {},
   "source": [
    "### SMU-MSDS-7337-Natural Language Processing HomeWork 2\n",
    "\n",
    "##### By-Rashmi Patel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d341ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.book import *\n",
    "from nltk.corpus import words\n",
    "import re\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0f378bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for removing the metadata\n",
    "def removeMeta(t):\n",
    "    start_line = \"*** START OF THIS PROJECT GUTENBERG EBOOK [A-Z ]+***\"\n",
    "    end_line = \"*** END OF THIS PROJECT GUTENBERG EBOOK [A-Z]+***\"\n",
    "    return re.split(end_line, re.split(start_line, text)[1])[0]\n",
    "\n",
    "# function for splitting the text\n",
    "def splitTxt(t):\n",
    "    return re.split(\"[^a-z']+\")\n",
    "\n",
    "# function for vocabulary count\n",
    "def vocabCount(t):\n",
    "    if t is str:\n",
    "        t = splitTxt(removeMeta(t))\n",
    "    return len(set(t))\n",
    "\n",
    "# function for lexical diversity\n",
    "def lexicalDiversity(t):\n",
    "    if t is str:\n",
    "        t = splitTxt(removeMeta(t))\n",
    "    return len(set(t)) / len(t)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce386efa",
   "metadata": {},
   "source": [
    "### Question 1: In Python, create a method for scoring the vocabulary size of a text, and normalize the score from 0 to 1. It does not matter what method you use for normalization as long as you explain it in a short paragraph. (Various methods will be discussed in the live session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f072b398",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = words.words()\n",
    "\n",
    "def vocabScore(t):\n",
    "    return vocabCount(t) / len(all_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "085b8187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08159722222222222\n"
     ]
    }
   ],
   "source": [
    "max_words = max([vocabScore(text1), vocabScore(text2), vocabScore(text3), vocabScore(text4),\n",
    "                 vocabScore(text5), vocabScore(text6), vocabScore(text7), vocabScore(text8),\n",
    "                 vocabScore(text9)])\n",
    "print(max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ef24a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moby Dick by Herman Melville 1851\n",
      "0.08159722222222222\n",
      "=============================\n",
      "Sense and Sensibility by Jane Austen 1811\n",
      "0.02886337523655042\n",
      "=============================\n",
      "The Book of Genesis\n",
      "0.011781055690727224\n"
     ]
    }
   ],
   "source": [
    "print(text1.name)\n",
    "print(vocabScore(text1))\n",
    "print('=============================')\n",
    "print(text2.name)\n",
    "print(vocabScore(text2))\n",
    "print('=============================')\n",
    "print(text3.name)\n",
    "print(vocabScore(text3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0038be4b",
   "metadata": {},
   "source": [
    "From the nltk.corpus.words.words() object, we are comparing the word count in a given text against the total number of words which is equal to 236376. \n",
    "\n",
    "This means is that the vocabulary score of a given text is its unique word count against that value. In this case, Moby Dick by Herman Melville 1851 has roughly 8% of the word count of the words object nltk.corpus.words.words().\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a583cc06",
   "metadata": {},
   "source": [
    "### Question 2: After consulting section 3.2 in chapter 1 of Bird-Klein, create a method for scoring the long-word vocabulary size of a text, and likewise normalize (and explain) the scoring as in step 1 above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60e8ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def longWordCnt(t, min_length = 10):\n",
    "    if t is str:\n",
    "        t = split_text(t)\n",
    "    \n",
    "    longWords = []\n",
    "    \n",
    "    for w in t:\n",
    "        if(len(w) >= min_length):\n",
    "            longWords.append(w)\n",
    "    \n",
    "    return vocabCount(longWords)\n",
    "    \n",
    "def longWordScore(t, min_length = 10):\n",
    "    count = 0\n",
    "    \n",
    "    for w in all_words:\n",
    "        if(len(w) >= min_length):\n",
    "            count += 1\n",
    "    \n",
    "    return float(longWordCnt(t, min_length)) / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ed2993f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2419 long words found in the text with the default minimum length of 10 and the long word score is 0.021070694400891956\n"
     ]
    }
   ],
   "source": [
    "print('There are',longWordCnt(text4),\n",
    "      'long words found in the text with the default minimum length of 10 and the long word score is'\n",
    "      ,longWordScore(text4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4043e2",
   "metadata": {},
   "source": [
    "The function longWordCnt() takes the text as parameter and perform counting each word of specified length (here the default is given of 10, which can be considered enough length for word\" in English).\n",
    "\n",
    "The function longWordScore() walks through the words() object, finds the total number of words of the specified length, and then divides the longWordCnt of the specified text by that value.\n",
    "\n",
    "For example, if words() object contains, 60 words of the appropriate length, while the specified text only had 12, the returned value would be .2 (12 / 60).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba219a8b",
   "metadata": {},
   "source": [
    "### Question 3: Now create a “text difficulty score” by combining the lexical diversity score from homework 1, and your normalized score of vocabulary size and long-word vocabulary size, in equal weighting. Explain what you see when this score is applied to same graded texts you used in homework 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6628ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "txtFile1 = './data/1.txt'\n",
    "txtFile3 = './data/3.txt'\n",
    "txtFile5 = './data/5.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92722da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-9bc09ee06a67>:1: DeprecationWarning: 'U' mode is deprecated\n",
      "  tf1 = open(txtFile1, 'rU')\n",
      "<ipython-input-9-9bc09ee06a67>:2: DeprecationWarning: 'U' mode is deprecated\n",
      "  tf3 = open(txtFile3, 'rU')\n",
      "<ipython-input-9-9bc09ee06a67>:3: DeprecationWarning: 'U' mode is deprecated\n",
      "  tf5 = open(txtFile5, 'rU')\n"
     ]
    }
   ],
   "source": [
    "tf1 = open(txtFile1, 'rU')\n",
    "tf3 = open(txtFile3, 'rU')\n",
    "tf5 = open(txtFile5, 'rU')\n",
    "\n",
    "raw = tf1.read()\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "txt1 = nltk.Text(tokens)\n",
    "\n",
    "raw = tf3.read()\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "txt3 = nltk.Text(tokens)\n",
    "\n",
    "raw = tf5.read()\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "txt5 = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa1984ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txtDiffScore(text):\n",
    "    return ((1/3)*lexicalDiversity(text) + (1/3)*vocabScore(text) + (1/3)*longWordScore(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f540e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text difficulty score for first grade reader is 0.05913730461208604\n",
      "The text difficulty score for third grade reader is 0.0488844200899054\n",
      "The text difficulty score for fifth grade reader is 0.06370412477093979\n"
     ]
    }
   ],
   "source": [
    "print('The text difficulty score for first grade reader is',txtDiffScore(txt1))\n",
    "print('The text difficulty score for third grade reader is',txtDiffScore(txt3))\n",
    "print('The text difficulty score for fifth grade reader is',txtDiffScore(txt5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbd9b09",
   "metadata": {},
   "source": [
    "The lexical diversity function used is slightly different then homework1 , since the first one didn't account for removing out non-alphabetic characters which means that words like 'how' and 'how? are not considered same word.\n",
    "\n",
    "To be clear, the files I'm using here are the McGuffey's Eclectic Readers, specifically the first, third and fifth grade readers.\n",
    "\n",
    "These values indicate that the first grade reader is slightly more difficult than the third grade reader, while the fifth grade reader is the most difficult of the set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0de22ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
